---
title: "ADS506 Final Proyect <Dataset name>"
author: "Jesse Gutierrez and Gonzalo Blazquez"
date: "`r Sys.Date()`"
output:
  word_document: default
  pdf_document: default
---

```{r}
# Load required packages
#library(ggseas)
library(ggplot2)
library(dplyr)
library(forecast)
library(lubridate)
library(tidyverse)
library(tidyr)
```

**Data Source**

The dataset was found under the UCI publicly available repository with additional supporting data at Mendeley Data. The information presented was gathered from four national pasta brands and is compiled of 118 daily time series SKU-level sales of pasta from 01/01/2014 to 31/12/2018. The dataset has 1798 observations for 118 different types of pastas with 118 rows representing daily sales at normal price and 118 columns for the sales with a promotion.

Besides univariate time series data, the quantity sold is integrated by information on the presence or the absence of a promotion.

<https://archive.ics.uci.edu/dataset/611/hierarchical+sales+data> <https://data.mendeley.com/datasets/njdkntcpc9/1>

**Importing the Data**

As the dataset file was not available for download under the UCI repository, an available CSV file was downloaded from Data Mendeley. This file was saved to a corresponding folder within the researchers computer and then imported into R using the ensuing code.

```{r}
# Import the potential data set
df <- read.csv('/Users/jesse/Downloads/Data for A machine learning approach for forecasting hierarchical time series/hierarchical_sales_data.csv')

# Display the first few rows to see the format of the dates included
head(df)
```

```{r}
# Display the total range of the dates for all 118 observations
start_date <- head(df$DATE, 1)
end_date <- tail(df$DATE, 1)
cat('The sales in this dataset range from ', start_date, 'to', end_date)
```

As evident with the above output, the sales the grocery store for the 118 items range from January 2, 2014 to December 31, 2018. This allows for five annual cycles of the sales of 118 different products within in a grocery store to compare the impact that the promotions made.

```{r}
#####GB#####
# Check for missing values
sum(is.na(df))
```

```{r}
# Convert the date column to the correct format
df$DATE <- as.Date(df$DATE)

# Display the output for verification
head(df)
```

```{r}
####GB####
date_sum <- df %>%
  select(starts_with("QTY_B")) %>%
  rowSums(na.rm = TRUE)

date_total <- data.frame(
  df$DATE,
  Sales_Sum = unlist(date_sum)
 
)
head(date_total)
```

```{r}
####GB####
#time series Total sales plot
sales.ts <- ts(date_total$Sales_Sum, start = c(2014,1), end = c(2018,12), freq = 12)
plot(sales.ts, main="Sales over time" ,
     xlab = "Time", ylab = "Sales",
     ylim = c(0, 1400), bty = "l")

ggseasonplot(sales.ts, year.labels=TRUE, year.labels.left=TRUE) +
  ylab("sales") +
  ggtitle("Seasonal plot: sales")
```

```{r}
####GB####
date_sum_b1 <- df %>%
  select(starts_with("QTY_B1")) %>%
  rowSums(na.rm = TRUE)
date_sum_b2 <- df %>%
  select(starts_with("QTY_B2")) %>%
  rowSums(na.rm = TRUE)
date_sum_b3 <- df %>%
  select(starts_with("QTY_B3")) %>%
  rowSums(na.rm = TRUE)
date_sum_b4 <- df %>%
  select(starts_with("QTY_B4")) %>%
  rowSums(na.rm = TRUE)

date_sum_pb1 <- df %>%
  select(starts_with("PROMO_B1")) %>%
  rowSums(na.rm = TRUE)
date_sum_pb2 <- df %>%
  select(starts_with("PROMO_B2")) %>%
  rowSums(na.rm = TRUE)
date_sum_pb3 <- df %>%
  select(starts_with("PROMO_B3")) %>%
  rowSums(na.rm = TRUE)
date_sum_pb4 <- df %>%
  select(starts_with("PROMO_B4")) %>%
  rowSums(na.rm = TRUE)


date_total_B <- data.frame(
  df$DATE,
  Sales_Sum = unlist(date_sum),
  Sales_Sum_b1 = unlist(date_sum_b1),
  Sales_Sum_b2 = unlist(date_sum_b2),
  Sales_Sum_b3 = unlist(date_sum_b3),
  Sales_Sum_b4 = unlist(date_sum_b4),
  Promo_Sum_b1 = unlist(date_sum_pb1),
  Promo_Sum_b2 = unlist(date_sum_pb2),
  Promo_Sum_b3 = unlist(date_sum_pb3),
  Promo_Sum_b4 = unlist(date_sum_pb4)
 
)

head(date_total_B, 20)
```

```{r}
####GB####
sales_b.ts <- ts(date_total_B[,c(3:6)], start = c(2014,1), end = c(2018,12), freq = 12)
is.ts(sales_b.ts)
ts.plot(sales_b.ts, col = 1:4, xlab = "Year", ylab = "Sales", main = "Sales by Brand")
legend("topleft", colnames(sales_b.ts), lty = 1, col = 1:4, bty = "n")
```

```{r}
####GB####
promo_b.ts <- ts(date_total_B[,c(7:10)], start = c(2014,1), end = c(2018,12), freq = 12)

ts.plot(promo_b.ts, col = 1:4, xlab = "Year", ylab = "Promos", main = "Promos by Brand")
legend("topleft", colnames(promo_b.ts), lty = 1, col = 1:4, bty = "n")
```




```{r}
# Calculate total sums for sales
sales_sum <- df %>%
  select(starts_with("QTY_B")) %>%
  summarise(across(everything(), sum))

# Calculate total sums for promotional sales
promo_sum <- df %>%
  select(starts_with("PROMO_B")) %>%
  summarise(across(everything(), sum))

# Create a data frame for the differences
annual_differences <- data.frame(
  Sales_Column = colnames(sales_sum),
  Sales_Sum = unlist(sales_sum),
  Promo_Sum = unlist(promo_sum),
  Promo_Makeup = round(unlist(promo_sum)/(unlist(sales_sum) + unlist(promo_sum)) * 100, 2)
)

# Sort by Sales-Sum in desc. order
annual_differences <- annual_differences %>%
  arrange(desc(Sales_Sum))

# Display the first 20 rows of the table
head(annual_differences, 20)
```

```{r}
# List the highest performing 10% of products
top_performers <- head(annual_differences, 12)

# Display the lowest performers
top_performers
```

```{r}
# List the lowest performing 10% of products
low_performers <- tail(annual_differences, 12)

# Display the lowest performers
low_performers
```

```{r}
# Combine the low and top performing products into a singular data frame for plotting
combined_data <- rbind(
  data.frame(Group = "Top Performers", Sales = top_performers$Sales_Sum, Promo = top_performers$Promo_Sum, Makeup = top_performers$Promo_Makeup),
  data.frame(Group = "Low Performers", Sales = low_performers$Sales_Sum, Promo = low_performers$Promo_Sum, Makeup = low_performers$Promo_Makeup)
)

# Create a boxplot to compare low & high performing product sales
ggplot(combined_data, aes(x = Group, y = Sales, fill = Group)) +
  geom_boxplot() +
  labs(x = "Performance Group", y = "Sales") +
  scale_fill_manual(values = c("Top Performers" = "blue", "Low Performers" = "red")) +
  ggtitle("Boxplot of Sales for Top vs. Low Performers") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )
```

To no surprise, the top performing products had a significantly higher range of sales compared to low performers.

```{r}
# Create a boxplot to compare low & high performing product Promo sales
ggplot(combined_data, aes(x = Group, y = Promo, fill = Group)) +
  geom_boxplot() +
  labs(x = "Performance Group", y = "Promo") +
  scale_fill_manual(values = c("Top Performers" = "blue", "Low Performers" = "red")) +
  ggtitle("Promo Sales Duration for Top vs. Low Performers") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )
```

This boxplot shows that top performing products also had significantly more promotional sales than the low performing. This is a value that we need to be mindful of the popularity of the given products that may drastically vary between groups.

```{r}
# Create a boxplot to compare low & high performing product Makeup sales
ggplot(combined_data, aes(x = Group, y = Makeup, fill = Group)) +
  geom_boxplot() +
  labs(x = "Performance Group", y = "Makeup") +
  scale_fill_manual(values = c("Top Performers" = "blue", "Low Performers" = "red")) +
  ggtitle("Promo Makeup for Top vs. Low Performers") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12)
  )
```

The last boxplot was interesting to see that the low performing products sales did predominately occur during a promotional period highlighting the significance of marketing efforts.

```{r}
# Create a stacked bar graph
ggplot(low_performers, aes(x = Sales_Column, y = Sales_Sum, fill = Promo_Sum)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(x = "Products", y = "Total Sales") +
  scale_fill_gradient(low = "blue", high = "red") +  # Customize the color scale
  ggtitle("Low Performing Product Sales Makeup") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12, angle = 90),
    axis.text.y = element_text(size = 12
  ))
```

When focusing on the lowest performing products, a focus was made on identifying items that received limited promotions. The idea is to identify products that may greatly benefit from marketing resources. In this instance, the products that appear to not have received much promotional resources is QTY_B2_12, QTY_B2_20, and QTY_B2_45.

```{r}
# Isolate the low performing products
low_performing_product <- low_performers$Sales_Column

# Replace "QTY" w/ "PROMO"
low_performing_product_promo <- sub("QTY", "PROMO", low_performing_product)

# Combine all column names we intend on keeping
selected_columns <- c("DATE", low_performing_product, low_performing_product_promo)

# Subset df to include only selected columns
low_perf_subset <- df[, selected_columns, drop = FALSE]

# Display results
head(low_perf_subset)
```

```{r}
# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B2_12", "PROMO_B2_12")
# Subset low_perf_subset to include only selected columns
QTY_B2_12 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B3_7", "PROMO_B3_7")
# Subset low_perf_subset to include only selected columns
QTY_B3_7 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B2_11", "PROMO_B2_11")
# Subset low_perf_subset to include only selected columns
QTY_B2_11 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B2_16", "PROMO_B2_16")
# Subset low_perf_subset to include only selected columns
QTY_B2_16 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B3_13", "PROMO_B3_13")
# Subset low_perf_subset to include only selected columns
QTY_B3_13 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B3_1", "PROMO_B3_1")
# Subset low_perf_subset to include only selected columns
QTY_B3_1 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B3_20", "PROMO_B3_20")
# Subset low_perf_subset to include only selected columns
QTY_B3_20 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B2_45", "PROMO_B2_45")
# Subset low_perf_subset to include only selected columns
QTY_B2_45 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B2_1", "PROMO_B2_1")
# Subset low_perf_subset to include only selected columns
QTY_B2_1 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B2_20", "PROMO_B2_20")
# Subset low_perf_subset to include only selected columns
QTY_B2_20 <- low_perf_subset[, selected_columns, drop = FALSE]

# Select corresponding columns to subset into the 12 low performers
selected_columns <- c("DATE", "QTY_B2_19", "PROMO_B2_19")
# Subset low_perf_subset to include only selected columns
QTY_B2_19 <- low_perf_subset[, selected_columns, drop = FALSE]
```

```{r}
# Select corresponding columns to subset into the 12 low performers
selected_columns_2_12 <- c("DATE", "QTY_B2_12", "PROMO_B2_12")
# Subset low_perf_subset to include only selected columns
QTY_B2_12 <- low_perf_subset[, selected_columns_2_12, drop = FALSE]

# Calculate metrics for QTY_B2_12
days_wo_promo_2_12 <- sum(QTY_B2_12$PROMO_B2_12 == 0)
days_w_promo_2_12 <- sum(QTY_B2_12$PROMO_B2_12 == 1)

avg_qty_promo_1_2_12 <- mean(QTY_B2_12$QTY_B2_12[QTY_B2_12$PROMO_B2_12 == 1])
avg_qty_promo_0_2_12 <- mean(QTY_B2_12$QTY_B2_12[QTY_B2_12$PROMO_B2_12 == 0])

# Create a data frame with the results for QTY_B2_12
result_table_2_12 <- data.frame(
  Product = "QTY_B2_12",
  Days_wo_Promo = days_wo_promo_2_12,
  Days_w_Promo = days_w_promo_2_12,
  Avg_QTY_Promo_1 = avg_qty_promo_1_2_12,
  Avg_QTY_Promo_0 = avg_qty_promo_0_2_12
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_3_6 <- c("DATE", "QTY_B3_6", "PROMO_B3_6")
# Subset low_perf_subset to include only selected columns
QTY_B3_6 <- low_perf_subset[, selected_columns_3_6, drop = FALSE]

# Calculate metrics for QTY_B3_6
days_wo_promo_3_6 <- sum(QTY_B3_6$PROMO_B3_6 == 0)
days_w_promo_3_6 <- sum(QTY_B3_6$PROMO_B3_6 == 1)

avg_qty_promo_1_3_6 <- mean(QTY_B3_6$QTY_B3_6[QTY_B3_6$PROMO_B3_6 == 1])
avg_qty_promo_0_3_6 <- mean(QTY_B3_6$QTY_B3_6[QTY_B3_6$PROMO_B3_6 == 0])

# Create a data frame with the results for QTY_B3_6
result_table_3_6 <- data.frame(
  Product = "QTY_B3_6",
  Days_wo_Promo = days_wo_promo_3_6,
  Days_w_Promo = days_w_promo_3_6,
  Avg_QTY_Promo_1 = avg_qty_promo_1_3_6,
  Avg_QTY_Promo_0 = avg_qty_promo_0_3_6
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_3_7 <- c("DATE", "QTY_B3_7", "PROMO_B3_7")
# Subset low_perf_subset to include only selected columns
QTY_B3_7 <- low_perf_subset[, selected_columns_3_7, drop = FALSE]

# Calculate metrics for QTY_B3_7
days_wo_promo_3_7 <- sum(QTY_B3_7$PROMO_B3_7 == 0)
days_w_promo_3_7 <- sum(QTY_B3_7$PROMO_B3_7 == 1)

avg_qty_promo_1_3_7 <- mean(QTY_B3_7$QTY_B3_7[QTY_B3_7$PROMO_B3_7 == 1])
avg_qty_promo_0_3_7 <- mean(QTY_B3_7$QTY_B3_7[QTY_B3_7$PROMO_B3_7 == 0])

# Create a data frame with the results for QTY_B3_7
result_table_3_7 <- data.frame(
  Product = "QTY_B3_7",
  Days_wo_Promo = days_wo_promo_3_7,
  Days_w_Promo = days_w_promo_3_7,
  Avg_QTY_Promo_1 = avg_qty_promo_1_3_7,
  Avg_QTY_Promo_0 = avg_qty_promo_0_3_7
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_2_11 <- c("DATE", "QTY_B2_11", "PROMO_B2_11")
# Subset low_perf_subset to include only selected columns
QTY_B2_11 <- low_perf_subset[, selected_columns_2_11, drop = FALSE]

# Calculate metrics for QTY_B2_11
days_wo_promo_2_11 <- sum(QTY_B2_11$PROMO_B2_11 == 0)
days_w_promo_2_11 <- sum(QTY_B2_11$PROMO_B2_11 == 1)

avg_qty_promo_1_2_11 <- mean(QTY_B2_11$QTY_B2_11[QTY_B2_11$PROMO_B2_11 == 1])
avg_qty_promo_0_2_11 <- mean(QTY_B2_11$QTY_B2_11[QTY_B2_11$PROMO_B2_11 == 0])

# Create a data frame with the results for QTY_B2_11
result_table_2_11 <- data.frame(
  Product = "QTY_B2_11",
  Days_wo_Promo = days_wo_promo_2_11,
  Days_w_Promo = days_w_promo_2_11,
  Avg_QTY_Promo_1 = avg_qty_promo_1_2_11,
  Avg_QTY_Promo_0 = avg_qty_promo_0_2_11
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_2_16 <- c("DATE", "QTY_B2_16", "PROMO_B2_16")
# Subset low_perf_subset to include only selected columns
QTY_B2_16 <- low_perf_subset[, selected_columns_2_16, drop = FALSE]

# Calculate metrics for QTY_B2_16
days_wo_promo_2_16 <- sum(QTY_B2_16$PROMO_B2_16 == 0)
days_w_promo_2_16 <- sum(QTY_B2_16$PROMO_B2_16 == 1)

avg_qty_promo_1_2_16 <- mean(QTY_B2_16$QTY_B2_16[QTY_B2_16$PROMO_B2_16 == 1])
avg_qty_promo_0_2_16 <- mean(QTY_B2_16$QTY_B2_16[QTY_B2_16$PROMO_B2_16 == 0])

# Create a data frame with the results for QTY_B2_16
result_table_2_16 <- data.frame(
  Product = "QTY_B2_16",
  Days_wo_Promo = days_wo_promo_2_16,
  Days_w_Promo = days_w_promo_2_16,
  Avg_QTY_Promo_1 = avg_qty_promo_1_2_16,
  Avg_QTY_Promo_0 = avg_qty_promo_0_2_16
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_3_13 <- c("DATE", "QTY_B3_13", "PROMO_B3_13")
# Subset low_perf_subset to include only selected columns
QTY_B3_13 <- low_perf_subset[, selected_columns_3_13, drop = FALSE]

# Calculate metrics for QTY_B3_13
days_wo_promo_3_13 <- sum(QTY_B3_13$PROMO_B3_13 == 0)
days_w_promo_3_13 <- sum(QTY_B3_13$PROMO_B3_13 == 1)

avg_qty_promo_1_3_13 <- mean(QTY_B3_13$QTY_B3_13[QTY_B3_13$PROMO_B3_13 == 1])
avg_qty_promo_0_3_13 <- mean(QTY_B3_13$QTY_B3_13[QTY_B3_13$PROMO_B3_13 == 0])

# Create a data frame with the results for QTY_B3_13
result_table_3_13 <- data.frame(
  Product = "QTY_B3_13",
  Days_wo_Promo = days_wo_promo_3_13,
  Days_w_Promo = days_w_promo_3_13,
  Avg_QTY_Promo_1 = avg_qty_promo_1_3_13,
  Avg_QTY_Promo_0 = avg_qty_promo_0_3_13
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_3_1 <- c("DATE", "QTY_B3_1", "PROMO_B3_1")
# Subset low_perf_subset to include only selected columns
QTY_B3_1 <- low_perf_subset[, selected_columns_3_1, drop = FALSE]

# Calculate metrics for QTY_B3_1
days_wo_promo_3_1 <- sum(QTY_B3_1$PROMO_B3_1 == 0)
days_w_promo_3_1 <- sum(QTY_B3_1$PROMO_B3_1 == 1)

avg_qty_promo_1_3_1 <- mean(QTY_B3_1$QTY_B3_1[QTY_B3_1$PROMO_B3_1 == 1])
avg_qty_promo_0_3_1 <- mean(QTY_B3_1$QTY_B3_1[QTY_B3_1$PROMO_B3_1 == 0])

# Create a data frame with the results for QTY_B3_1
result_table_3_1 <- data.frame(
  Product = "QTY_B3_1",
  Days_wo_Promo = days_wo_promo_3_1,
  Days_w_Promo = days_w_promo_3_1,
  Avg_QTY_Promo_1 = avg_qty_promo_1_3_1,
  Avg_QTY_Promo_0 = avg_qty_promo_0_3_1
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_3_20 <- c("DATE", "QTY_B3_20", "PROMO_B3_20")
# Subset low_perf_subset to include only selected columns
QTY_B3_20 <- low_perf_subset[, selected_columns_3_20, drop = FALSE]

# Calculate metrics for QTY_B3_20
days_wo_promo_3_20 <- sum(QTY_B3_20$PROMO_B3_20 == 0)
days_w_promo_3_20 <- sum(QTY_B3_20$PROMO_B3_20 == 1)

avg_qty_promo_1_3_20 <- mean(QTY_B3_20$QTY_B3_20[QTY_B3_20$PROMO_B3_20 == 1])
avg_qty_promo_0_3_20 <- mean(QTY_B3_20$QTY_B3_20[QTY_B3_20$PROMO_B3_20 == 0])

# Create a data frame with the results for QTY_B3_20
result_table_3_20 <- data.frame(
  Product = "QTY_B3_20",
  Days_wo_Promo = days_wo_promo_3_20,
  Days_w_Promo = days_w_promo_3_20,
  Avg_QTY_Promo_1 = avg_qty_promo_1_3_20,
  Avg_QTY_Promo_0 = avg_qty_promo_0_3_20
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_2_45 <- c("DATE", "QTY_B2_45", "PROMO_B2_45")
# Subset low_perf_subset to include only selected columns
QTY_B2_45 <- low_perf_subset[, selected_columns_2_45, drop = FALSE]

# Calculate metrics for QTY_B2_45
days_wo_promo_2_45 <- sum(QTY_B2_45$PROMO_B2_45 == 0)
days_w_promo_2_45 <- sum(QTY_B2_45$PROMO_B2_45 == 1)

avg_qty_promo_1_2_45 <- mean(QTY_B2_45$QTY_B2_45[QTY_B2_45$PROMO_B2_45 == 1])
avg_qty_promo_0_2_45 <- mean(QTY_B2_45$QTY_B2_45[QTY_B2_45$PROMO_B2_45 == 0])

# Create a data frame with the results for QTY_B2_45
result_table_2_45 <- data.frame(
  Product = "QTY_B2_45",
  Days_wo_Promo = days_wo_promo_2_45,
  Days_w_Promo = days_w_promo_2_45,
  Avg_QTY_Promo_1 = avg_qty_promo_1_2_45,
  Avg_QTY_Promo_0 = avg_qty_promo_0_2_45
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_2_1 <- c("DATE", "QTY_B2_1", "PROMO_B2_1")
# Subset low_perf_subset to include only selected columns
QTY_B2_1 <- low_perf_subset[, selected_columns_2_1, drop = FALSE]

# Calculate metrics for QTY_B2_1
days_wo_promo_2_1 <- sum(QTY_B2_1$PROMO_B2_1 == 0)
days_w_promo_2_1 <- sum(QTY_B2_1$PROMO_B2_1 == 1)

avg_qty_promo_1_2_1 <- mean(QTY_B2_1$QTY_B2_1[QTY_B2_1$PROMO_B2_1 == 1])
avg_qty_promo_0_2_1 <- mean(QTY_B2_1$QTY_B2_1[QTY_B2_1$PROMO_B2_1 == 0])

# Create a data frame with the results for QTY_B2_1
result_table_2_1 <- data.frame(
  Product = "QTY_B2_1",
  Days_wo_Promo = days_wo_promo_2_1,
  Days_w_Promo = days_w_promo_2_1,
  Avg_QTY_Promo_1 = avg_qty_promo_1_2_1,
  Avg_QTY_Promo_0 = avg_qty_promo_0_2_1
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_2_20 <- c("DATE", "QTY_B2_20", "PROMO_B2_20")
# Subset low_perf_subset to include only selected columns
QTY_B2_20 <- low_perf_subset[, selected_columns_2_20, drop = FALSE]

# Calculate metrics for QTY_B2_20
days_wo_promo_2_20 <- sum(QTY_B2_20$PROMO_B2_20 == 0)
days_w_promo_2_20 <- sum(QTY_B2_20$PROMO_B2_20 == 1)

avg_qty_promo_1_2_20 <- mean(QTY_B2_20$QTY_B2_20[QTY_B2_20$PROMO_B2_20 == 1])
avg_qty_promo_0_2_20 <- mean(QTY_B2_20$QTY_B2_20[QTY_B2_20$PROMO_B2_20 == 0])

# Create a data frame with the results for QTY_B2_20
result_table_2_20 <- data.frame(
  Product = "QTY_B2_20",
  Days_wo_Promo = days_wo_promo_2_20,
  Days_w_Promo = days_w_promo_2_20,
  Avg_QTY_Promo_1 = avg_qty_promo_1_2_20,
  Avg_QTY_Promo_0 = avg_qty_promo_0_2_20
)

# Select corresponding columns to subset into the 12 low performers
selected_columns_2_19 <- c("DATE", "QTY_B2_19", "PROMO_B2_19")
# Subset low_perf_subset to include only selected columns
QTY_B2_19 <- low_perf_subset[, selected_columns_2_19, drop = FALSE]

# Calculate metrics for QTY_B2_19
days_wo_promo_2_19 <- sum(QTY_B2_19$PROMO_B2_19 == 0)
days_w_promo_2_19 <- sum(QTY_B2_19$PROMO_B2_19 == 1)

avg_qty_promo_1_2_19 <- mean(QTY_B2_19$QTY_B2_19[QTY_B2_19$PROMO_B2_19 == 1])
avg_qty_promo_0_2_19 <- mean(QTY_B2_19$QTY_B2_19[QTY_B2_19$PROMO_B2_19 == 0])

# Create a data frame with the results for QTY_B2_19
result_table_2_19 <- data.frame(
  Product = "QTY_B2_19",
  Days_wo_Promo = days_wo_promo_2_19,
  Days_w_Promo = days_w_promo_2_19,
  Avg_QTY_Promo_1 = avg_qty_promo_1_2_19,
  Avg_QTY_Promo_0 = avg_qty_promo_0_2_19
)

# Combine all results into a single table
result_table_combined <- rbind(
  result_table_2_12, result_table_3_6, result_table_3_7, result_table_2_11, result_table_2_16,
  result_table_3_13, result_table_3_1, result_table_3_20, result_table_2_45, result_table_2_1,
  result_table_2_20, result_table_2_19
)

# Display results
result_table_combined
```

```{r}
# Melt the data to long format for easy plotting
result_table_combined_long <- reshape2::melt(result_table_combined, id.vars = "Product")

# Filter the columns
result_table_combined_long_filtered <- result_table_combined_long %>%
  filter(variable %in% c("Avg_QTY_Promo_1", "Avg_QTY_Promo_0"))

# Plot using ggplot
ggplot(result_table_combined_long_filtered, aes(x = Product, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Quantity for Promo Types",
       x = "Product",
       y = "Average Quantity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
As the plot can show, the majority of sales are dependent on there being a promotion. This is particularly true for product B2_12 as all sales were solely when there was a promotion. 

```{r}
# Melt the data to long format for easy plotting
result_table_combined_long <- reshape2::melt(result_table_combined, id.vars = "Product")

# Filter the columns
result_table_combined_long_filtered <- result_table_combined_long %>%
  filter(variable %in% c("Days_wo_Promo", "Days_w_Promo"))

# Plot using ggplot
ggplot(result_table_combined_long_filtered, aes(x = Product, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Days with and without Promo",
       x = "Product",
       y = "Count of Days") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```
This plot displays the makeup of total days each product sold with and without a promotion. This can illustrate the difference in promotional resource allocation between the low performing products

**Time Series Plot**

```{r}
# Isolate the dataset to just include the product of interest
low_performing_product <- df[, c("DATE", "QTY_B2_12", "PROMO_B2_12")]

# Display the subset w/ the isolated product
head(low_performing_product)
```

```{r}
# Create bar plot comparing total days w/ promotion
ggplot(low_performing_product, aes(x = factor(PROMO_B2_12), y = QTY_B2_12, fill = factor(PROMO_B2_12))) +
  geom_bar(stat = "summary", fun = "sum", position = "dodge") +
  labs(title = "Total Values of QTY_B2_12 by PROMO_B2_12",
       x = "PROMO_B2_12",
       y = "Total QTY_B2_12") +
  scale_fill_manual(values = c("lightblue", "lightgreen")) +
  theme_minimal()
```

```{r}
# Extract year & month from DATE
low_performing_product$YearMonth <- format(low_performing_product$DATE, "%Y-%m")
low_performing_product$Year <- format(low_performing_product$DATE, "%Y")

# Create overlapping line plots for each year with months on the x-axis
ggplot(low_performing_product, aes(x = YearMonth, y = PROMO_B2_12, group = Year, color = Year)) +
  geom_line() +
  labs(title = "Overlapping Line Plots of PROMO_B2_12 by Year with Months",
       x = "Month",
       y = "PROMO_B2_12") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        axis.text.x.bottom = element_text(size = 8),
        axis.text.x.top = element_text(size = 8)) +
  coord_cartesian(ylim = c(0, 1))
```

```{r}
# Calculate sum of PROMO_B2_12 for each month & year
sum_qty_by_month <- low_performing_product %>%
  group_by(month = month(DATE, label = TRUE, abbr = FALSE), year = year(DATE)) %>%
  summarize(sum_qty = sum(PROMO_B2_12), .groups = 'drop')

# Create a line plot w/ sum of PROMO_B2_12 for each month & year
ggplot(sum_qty_by_month, aes(x = month, y = sum_qty, color = as.factor(year), group = year)) +
  geom_line() +
  geom_point() +
  labs(title = "Sum of PROMO_B2_12 Sales Over Time",
       x = "Month",
       y = "Sum of PROMO_B2_12",
       color = "Year") +
  theme_minimal() +
  scale_color_discrete(name = "Year") +
  theme(legend.position = "top") +
  theme(legend.title = element_blank()) +
  theme(plot.title = element_text(size = 16, face = "bold")) +
  theme(legend.text = element_text(size = 12)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme(axis.text = element_text(size = 12)) +
  theme(axis.title = element_text(size = 14))
```

```{r}
# Calculate sum of QTY_B2_12 for each month & year
sum_qty_by_month <- low_performing_product %>%
  group_by(month = month(DATE, label = TRUE, abbr = FALSE), year = year(DATE)) %>%
  summarize(sum_qty = sum(QTY_B2_12), .groups = 'drop')

# Create a line plot w/ sum of QTY_B2_12 for each month & year
ggplot(sum_qty_by_month, aes(x = month, y = sum_qty, color = as.factor(year), group = year)) +
  geom_line() +
  geom_point() +
  labs(title = "Sum of QTY_B2_12 Sales Over Time",
       x = "Month",
       y = "Sum of QTY_B2_12",
       color = "Year") +
  theme_minimal() +
  scale_color_discrete(name = "Year") +
  theme(legend.position = "top") +
  theme(legend.title = element_blank()) +
  theme(plot.title = element_text(size = 16, face = "bold")) +
  theme(legend.text = element_text(size = 12)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  
  theme(axis.text = element_text(size = 12)) +
  theme(axis.title = element_text(size = 14))
```

**Splitting the data**

```{r}
# Split the data into training (2014-01-02 to 2017-12-31) and validation (2018-01-31 to 2018-12-31)
training_set <- subset(df, DATE >= "2014-01-02" & DATE <= "2017-12-31")
validation_set <- subset(df, DATE >= "2018-01-31" & DATE <= "2018-12-31")

# Display the dimensions of the training and validation sets
cat("Training Set Dimensions:", dim(training_set), "\n")
cat("Validation Set Dimensions:", dim(validation_set), "\n")
```

**Building Time Series Models**

```{r}
# Create time series object for training set - QTY_B2_12
ts_train_qty <- ts(training_set$QTY_B2_12, frequency = 365)

# Fit an ARIMA model to training subset
arima_model_qty <- auto.arima(ts_train_qty)

# Plot Autocorrelation Function (ACF)
acf(ts_train_qty, main = "ACF - QTY_B2_12")

# Plot Partial Autocorrelation Function (PACF)
pacf(ts_train_qty, main = "PACF - QTY_B2_12")
```

```{r}
# Forecast on the validation data
forecast_validation_qty <- forecast(arima_model_qty, h = length(validation_set))

# Display & plot forecast
print(forecast_validation_qty)
plot(forecast_validation_qty)

# Evaluate model's training set performance
training_residuals_qty <- residuals(arima_model_qty)
training_rmse_qty <- sqrt(mean(training_residuals_qty^2))
cat("Training Set RMSE for QTY_B2_12:", training_rmse_qty, "\n")

# Evaluate model's validation set performance
validation_residuals_qty <- validation_set$QTY_B2_12 - forecast_validation_qty$mean[1:length(validation_set)]
validation_rmse_qty <- sqrt(mean(validation_residuals_qty^2))
cat("Validation Set RMSE for QTY_B2_12:", validation_rmse_qty, "\n")

# Create time series object for training set - PROMO_B2_12
ts_train_promo <- ts(training_set$PROMO_B2_12, frequency = 365)

# Fit an ARIMA model to training subset
arima_model_promo <- auto.arima(ts_train_promo)

# Forecast on the validation data
forecast_validation_promo <- forecast(arima_model_promo, h = length(validation_set))

# Display & plot forecast
print(forecast_validation_promo)
plot(forecast_validation_promo)

# Evaluate model's training set performance
training_residuals_promo <- residuals(arima_model_promo)
training_rmse_promo <- sqrt(mean(training_residuals_promo^2))
cat("Training Set RMSE for PROMO_B2_12:", training_rmse_promo, "\n")

# Evaluate model's validation set performance
validation_residuals_promo <- validation_set$PROMO_B2_12 - forecast_validation_promo$mean[1:length(validation_set)]
validation_rmse_promo <- sqrt(mean(validation_residuals_promo^2))
cat("Validation Set RMSE for PROMO_B2_12:", validation_rmse_promo, "\n")
```

### ARIMA (1, 1, 0) Configuration can 

```{r}
# Fit an ARIMA(1, 1, 0) model to training subset for QTY_B2_12
arima_model_qty_110 <- arima(ts_train_qty, order = c(1, 1, 0))

# Forecast on the validation data
forecast_validation_qty_110 <- forecast(arima_model_qty_110, h = length(validation_set))

# Display & plot forecast
print(forecast_validation_qty_110)
plot(forecast_validation_qty_110)

# Evaluate model's training set performance
training_residuals_qty_110 <- residuals(arima_model_qty_110)
training_rmse_qty_110 <- sqrt(mean(training_residuals_qty_110^2))
cat("Training Set RMSE for QTY_B2_12 (ARIMA(1, 1, 0)):", training_rmse_qty_110, "\n")

# Evaluate model's validation set performance
validation_residuals_qty_110 <- validation_set$QTY_B2_12 - forecast_validation_qty_110$mean[1:length(validation_set)]
validation_rmse_qty_110 <- sqrt(mean(validation_residuals_qty_110^2))
cat("Validation Set RMSE for QTY_B2_12 (ARIMA(1, 1, 0)):", validation_rmse_qty_110, "\n")
```

### ARIMA (1, 1, 1) Configuration  

```{r}
# Fit an ARIMA(1, 1, 1) model to training subset for QTY_B2_12
arima_model_qty_111 <- arima(ts_train_qty, order = c(1, 1, 1))

# Forecast on the validation data
forecast_validation_qty_111 <- forecast(arima_model_qty_111, h = length(validation_set))

# Display & plot forecast
print(forecast_validation_qty_111)
plot(forecast_validation_qty_111)

# Evaluate model's training set performance
training_residuals_qty_111 <- residuals(arima_model_qty_111)
training_rmse_qty_111 <- sqrt(mean(training_residuals_qty_111^2))
cat("Training Set RMSE for QTY_B2_12 (ARIMA(1, 1, 1)):", training_rmse_qty_111, "\n")

# Evaluate model's validation set performance
validation_residuals_qty_111 <- validation_set$QTY_B2_12 - forecast_validation_qty_111$mean[1:length(validation_set)]
validation_rmse_qty_111 <- sqrt(mean(validation_residuals_qty_111^2))
cat("Validation Set RMSE for QTY_B2_12 (ARIMA(1, 1, 1)):", validation_rmse_qty_111, "\n")
```

## Linear regression model for QTY_B2_12

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_12 ~ DATE + PROMO_B2_12, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_12)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_12",
       x = "Date",
       y = "QTY_B2_12") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_12 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```
This shows that the sales of product B2_12 have been trending downward through time at a rate of 0.000279 per date, but this value does increase by 1.554 during a promo.

## Linear regression model for QTY_B3_6

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B3_6 ~ DATE + PROMO_B3_6, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B3_6)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B3_6",
       x = "Date",
       y = "QTY_B3_6") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B3_6 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B3_7

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B3_7 ~ DATE + PROMO_B3_7, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B3_7)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B3_7",
       x = "Date",
       y = "QTY_B3_7") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B3_7 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```
Promotional efforts yielded the highest impact on this product as it is estimated to increase sales by 3 units each day.

## Linear regression model for QTY_B2_11

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_11 ~ DATE + PROMO_B2_11, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_11)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_11",
       x = "Date",
       y = "QTY_B2_11") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_11 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B2_16

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_16 ~ DATE + PROMO_B2_16, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_16)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_16",
       x = "Date",
       y = "QTY_B2_16") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_16 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B3_13

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B3_13 ~ DATE + PROMO_B3_13, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B3_13)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B3_13",
       x = "Date",
       y = "QTY_B3_13") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B3_13 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B3_1

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B3_1 ~ DATE + PROMO_B3_1, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B3_1)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B3_1",
       x = "Date",
       y = "QTY_B3_1") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B3_1 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B3_20

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B3_20 ~ DATE + PROMO_B3_20, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B3_20)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B3_20",
       x = "Date",
       y = "QTY_B3_20") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B3_20 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B2_45

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_45 ~ DATE + PROMO_B2_45, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_45)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_45",
       x = "Date",
       y = "QTY_B2_45") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_45 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B2_45

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_45 ~ DATE + PROMO_B2_45, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_45)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_45",
       x = "Date",
       y = "QTY_B2_45") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_45 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B2_1

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_1 ~ DATE + PROMO_B2_1, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_1)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_1",
       x = "Date",
       y = "QTY_B2_1") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_1 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B2_20

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_20 ~ DATE + PROMO_B2_20, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_20)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_20",
       x = "Date",
       y = "QTY_B2_20") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_20 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Linear regression model for QTY_B2_19

```{r}
# Build a linear regression model
linear_model <- lm(QTY_B2_19 ~ DATE + PROMO_B2_19, data = training_set)

# Display the summary of the model
summary(linear_model)

# Make predictions on the validation data
validation_set$predicted_qty <- predict(linear_model, newdata = validation_set)

# Plot actual vs. predicted
ggplot(validation_set, aes(x = DATE, y = QTY_B2_19)) +
  geom_line(aes(y = predicted_qty), color = "blue") +
  labs(title = "Linear Regression Model - Actual vs. Predicted QTY_B2_19",
       x = "Date",
       y = "QTY_B2_19") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mean((validation_set$QTY_B2_19 - validation_set$predicted_qty)^2))

# Print the RMSE
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
```

## Created a NN model for product that yielded the highest increase in sales when promoted (3.2788210)

```{r}
# Assuming you have the neuralnet library installed, if not, install it using install.packages("neuralnet")
library(neuralnet)
library(ggplot2)

# Convert variables to numeric
training_set$DATE <- as.numeric(training_set$DATE)
training_set$PROMO_B3_7 <- as.numeric(training_set$PROMO_B3_7)
training_set$QTY_B3_7 <- as.numeric(training_set$QTY_B3_7)
validation_set$DATE <- as.numeric(validation_set$DATE)
validation_set$PROMO_B3_7 <- as.numeric(validation_set$PROMO_B3_7)
validation_set$QTY_B3_7 <- as.numeric(validation_set$QTY_B3_7)

# Build a neural network model
neural_model <- neuralnet(QTY_B3_7 ~ DATE + PROMO_B3_7, data = training_set, hidden = c(5, 3))

# Make predictions on the validation data
validation_set$predicted_qty_neural <- predict(neural_model, newdata = validation_set)

# Plot actual vs. predicted for the neural network
ggplot(validation_set, aes(x = DATE, y = QTY_B3_7)) +
  geom_line(aes(y = predicted_qty_neural), color = "red") +
  labs(title = "Neural Network Model - Actual vs. Predicted QTY_B3_7",
       x = "Date",
       y = "QTY_B3_7") +
  theme_minimal()

# Calculate Root Mean Squared Error (RMSE) for the neural network
rmse_neural <- sqrt(mean((validation_set$QTY_B3_7 - validation_set$predicted_qty_neural)^2))

# Print the RMSE for the neural network
cat("Root Mean Squared Error (RMSE) for Neural Network:", rmse_neural, "\n")
```
# Developing new appraoch

```{r}
####GB####
promo_b.ts <- ts(date_total_B[,c(7:7)], start = c(2014,1), end = c(2018,12), freq = 12)

promo_b.ts
```

```{r}
# Split the data into 'no_promo' (January 2014 to June 2017) and 'promo' (July 2017 to December 2018)
no_promo <- subset(date_total_B, df.DATE >= as.Date("2014-01-01") & df.DATE <= as.Date("2017-06-30"))
promo <- subset(date_total_B, df.DATE >= as.Date("2017-07-01") & df.DATE <= as.Date("2018-12-31"))
```

```{r}
no_promo
```

# Updated code

```{r}
B1_sales <- df[, c(
  "DATE", "QTY_B1_1", "QTY_B1_2", "QTY_B1_3", "QTY_B1_4", "QTY_B1_5", "QTY_B1_6", "QTY_B1_7", "QTY_B1_8", "QTY_B1_9", "QTY_B1_10", "QTY_B1_11", "QTY_B1_12", "QTY_B1_13", 
  "QTY_B1_14", "QTY_B1_15", "QTY_B1_16", "QTY_B1_17", "QTY_B1_18", "QTY_B1_19", "QTY_B1_20", "QTY_B1_21", "QTY_B1_22", "QTY_B1_23", "QTY_B1_24", "QTY_B1_25", "QTY_B1_26", 
  "QTY_B1_27", "QTY_B1_28", "QTY_B1_29", "QTY_B1_30", "QTY_B1_31", "QTY_B1_32", "QTY_B1_33", "QTY_B1_34", "QTY_B1_35", "QTY_B1_36", "QTY_B1_37", "QTY_B1_38", "QTY_B1_39", 
  "QTY_B1_40", "QTY_B1_41", "QTY_B1_42", "PROMO_B1_1", "PROMO_B1_2", "PROMO_B1_3", "PROMO_B1_4", "PROMO_B1_5", "PROMO_B1_6", "PROMO_B1_7", "PROMO_B1_8", "PROMO_B1_9", 
  "PROMO_B1_10", "PROMO_B1_11", "PROMO_B1_12", "PROMO_B1_13", "PROMO_B1_14", "PROMO_B1_15", "PROMO_B1_16", "PROMO_B1_17", "PROMO_B1_18", "PROMO_B1_19", "PROMO_B1_20", 
  "PROMO_B1_21", "PROMO_B1_22", "PROMO_B1_23", "PROMO_B1_24", "PROMO_B1_25", "PROMO_B1_26", "PROMO_B1_27", "PROMO_B1_28", "PROMO_B1_29", "PROMO_B1_30", "PROMO_B1_31", 
  "PROMO_B1_32", "PROMO_B1_33", "PROMO_B1_34", "PROMO_B1_35", "PROMO_B1_36", "PROMO_B1_37", "PROMO_B1_38", "PROMO_B1_39", "PROMO_B1_40", "PROMO_B1_41", "PROMO_B1_42"
)]

B2_sales <- df[, c(
  "DATE", "QTY_B2_1", "QTY_B2_2", "QTY_B2_3", "QTY_B2_4", "QTY_B2_5", "QTY_B2_6", "QTY_B2_7", "QTY_B2_8", "QTY_B2_9", "QTY_B2_10", "QTY_B2_11", "QTY_B2_12", "QTY_B2_13", 
  "QTY_B2_14", "QTY_B2_15", "QTY_B2_16", "QTY_B2_17", "QTY_B2_18", "QTY_B2_19", "QTY_B2_20", "QTY_B2_21", "QTY_B2_22", "QTY_B2_23", "QTY_B2_24", "QTY_B2_25", "QTY_B2_26", 
  "QTY_B2_27", "QTY_B2_28", "QTY_B2_29", "QTY_B2_30", "QTY_B2_31", "QTY_B2_32", "QTY_B2_33", "QTY_B2_34", "QTY_B2_35", "QTY_B2_36", "QTY_B2_37", "QTY_B2_38", "QTY_B2_39", 
  "QTY_B2_40", "QTY_B2_41", "QTY_B2_42", "QTY_B2_43", "QTY_B2_44", "QTY_B2_45", "PROMO_B2_1", "PROMO_B2_2", "PROMO_B2_3", "PROMO_B2_4", "PROMO_B2_5", "PROMO_B2_6", 
  "PROMO_B2_7", "PROMO_B2_8", "PROMO_B2_9", "PROMO_B2_10", "PROMO_B2_11", "PROMO_B2_12", "PROMO_B2_13", "PROMO_B2_14", "PROMO_B2_15", "PROMO_B2_16", "PROMO_B2_17", 
  "PROMO_B2_18", "PROMO_B2_19", "PROMO_B2_20", "PROMO_B2_21", "PROMO_B2_22", "PROMO_B2_23", "PROMO_B2_24", "PROMO_B2_25", "PROMO_B2_26", "PROMO_B2_27", "PROMO_B2_28", 
  "PROMO_B2_29", "PROMO_B2_30", "PROMO_B2_31", "PROMO_B2_32", "PROMO_B2_33", "PROMO_B2_34", "PROMO_B2_35", "PROMO_B2_36", "PROMO_B2_37", "PROMO_B2_38", "PROMO_B2_39", 
  "PROMO_B2_40", "PROMO_B2_41", "PROMO_B2_42", "PROMO_B2_43", "PROMO_B2_44", "PROMO_B2_45"
)]

B3_sales <- df[, c(
  "DATE", "QTY_B3_1", "QTY_B3_2", "QTY_B3_3", "QTY_B3_4", "QTY_B3_5", "QTY_B3_6", "QTY_B3_7", "QTY_B3_8", "QTY_B3_9", "QTY_B3_10", "QTY_B3_11", "QTY_B3_12", "QTY_B3_13", 
  "QTY_B3_14", "QTY_B3_15", "QTY_B3_16", "QTY_B3_17", "QTY_B3_18", "QTY_B3_19", "QTY_B3_20", "QTY_B3_21", "PROMO_B3_1", "PROMO_B3_2", "PROMO_B3_3", "PROMO_B3_4", 
  "PROMO_B3_5", "PROMO_B3_6", "PROMO_B3_7", "PROMO_B3_8", "PROMO_B3_9", "PROMO_B3_10", "PROMO_B3_11", "PROMO_B3_12", "PROMO_B3_13", "PROMO_B3_14", "PROMO_B3_15", 
  "PROMO_B3_16", "PROMO_B3_17", "PROMO_B3_18", "PROMO_B3_19", "PROMO_B3_20", "PROMO_B3_21"
)]

B4_sales <- df[, c(
  "DATE", "QTY_B4_1", "QTY_B4_2", "QTY_B4_3", "QTY_B4_4", "QTY_B4_5", "QTY_B4_6", "QTY_B4_7", "QTY_B4_8", "QTY_B4_9", "QTY_B4_10", "PROMO_B4_1", "PROMO_B4_2", 
  "PROMO_B4_3", "PROMO_B4_4", "PROMO_B4_5", "PROMO_B4_6", "PROMO_B4_7", "PROMO_B4_8", "PROMO_B4_9", "PROMO_B4_10"
)]

# Count the number of column names that start with "QTY_" for each data subset
qty_columns_b1 <- sum(grepl("^QTY_", colnames(B1_sales)))
qty_columns_b2 <- sum(grepl("^QTY_", colnames(B2_sales)))
qty_columns_b3 <- sum(grepl("^QTY_", colnames(B3_sales)))
qty_columns_b4 <- sum(grepl("^QTY_", colnames(B4_sales)))

# Display the results
cat("Number of columns starting with 'QTY_' in B1_sales:", qty_columns_b1, "\n")
cat("Number of columns starting with 'QTY_' in B2_sales:", qty_columns_b2, "\n")
cat("Number of columns starting with 'QTY_' in B3_sales:", qty_columns_b3, "\n")
cat("Number of columns starting with 'QTY_' in B4_sales:", qty_columns_b4, "\n")
```

```{r}
# Calculate the total sum for columns starting with "QTY_" in each data subset
total_qty_b1 <- sum(B1_sales[, grepl("^QTY_", colnames(B1_sales))])
total_qty_b2 <- sum(B2_sales[, grepl("^QTY_", colnames(B2_sales))])
total_qty_b3 <- sum(B3_sales[, grepl("^QTY_", colnames(B3_sales))])
total_qty_b4 <- sum(B4_sales[, grepl("^QTY_", colnames(B4_sales))])

# Create a bar plot for comparison
barplot(c(total_qty_b1, total_qty_b2, total_qty_b3, total_qty_b4),
        names.arg = c("B1_sales", "B2_sales", "B3_sales", "B4_sales"),
        col = "skyblue",
        main = "Total Sum for Columns Starting with 'QTY_' in Each Subset",
        xlab = "Data Subset",
        ylab = "Total Sum")

# Add values inside the bars
text(c(1, 2, 3, 4), c(total_qty_b1, total_qty_b2, total_qty_b3, total_qty_b4),
     labels = c(total_qty_b1, total_qty_b2, total_qty_b3, total_qty_b4),
     pos = ifelse(c(total_qty_b1, total_qty_b2, total_qty_b3, total_qty_b4) < 10000, 3, 1),
     col = "black", cex = 1.2)
```

```{r}
# Calculate the total sum for columns starting with "PROMO_" in each data subset
total_PROMO_b1 <- sum(B1_sales[, grepl("^PROMO_", colnames(B1_sales))])
total_PROMO_b2 <- sum(B2_sales[, grepl("^PROMO_", colnames(B2_sales))])
total_PROMO_b3 <- sum(B3_sales[, grepl("^PROMO_", colnames(B3_sales))])
total_PROMO_b4 <- sum(B4_sales[, grepl("^PROMO_", colnames(B4_sales))])

# Create a bar plot for comparison
barplot(c(total_PROMO_b1, total_PROMO_b2, total_PROMO_b3, total_PROMO_b4),
        names.arg = c("B1_sales", "B2_sales", "B3_sales", "B4_sales"),
        col = "skyblue",
        main = "Total Sum for Columns Starting with 'PROMO_' in Each Subset",
        xlab = "Data Subset",
        ylab = "Total Sum")

# Add values inside the bars
text(c(1, 2, 3, 4), c(total_PROMO_b1, total_PROMO_b2, total_PROMO_b3, total_PROMO_b4),
     labels = c(total_PROMO_b1, total_PROMO_b2, total_PROMO_b3, total_PROMO_b4),
     pos = ifelse(c(total_PROMO_b1, total_PROMO_b2, total_PROMO_b3, total_PROMO_b4) < 10000, 3, 1),
     col = "black", cex = 1.2)
```

## Show the distribution of promotions

```{r}
# Filter columns starting w/ "PROMO_"
promo_columns <- grep("^PROMO_", colnames(B1_sales), value = TRUE)

# Calculate the sum for each column
promo_sums <- colSums(B1_sales[promo_columns])

# Display distribution table
summary(promo_sums)
```
As we can see the median that will be used is 332

```{r}
# Calculate total column sums for "PROMO_" columns in B1_sales
promo_totals <- colSums(B1_sales[, grepl("^PROMO_", colnames(B1_sales))])

# Calculate the 50th percentile
percentile_50 <- quantile(promo_totals, 0.5)

# Divide into subsets based on the 50th percentile
above_50_subset <- promo_totals[promo_totals > percentile_50]
below_50_subset <- promo_totals[promo_totals <= percentile_50]
```

```{r}
# Display the columns & total sum previously calculated
above_50_subset
```

```{r}
# Display the columns & total sum previously calculated
below_50_subset
```

```{r}
# Split into the two datasets
B1_above <- df[, c("DATE", "QTY_B1_2",  "QTY_B1_3",  "QTY_B1_8",  "QTY_B1_9", "QTY_B1_11", "QTY_B1_12", "QTY_B1_13", "QTY_B1_14", "QTY_B1_20", "QTY_B1_22", "QTY_B1_23", "QTY_B1_24", "QTY_B1_28")]
B1_below <- df[, c("DATE", "QTY_B1_1",  "QTY_B1_4",  "QTY_B1_5",  "QTY_B1_6",  "QTY_B1_7", "QTY_B1_10", "QTY_B1_15", "QTY_B1_16", "QTY_B1_17", "QTY_B1_18", "QTY_B1_19", "QTY_B1_21", "QTY_B1_25", "QTY_B1_26", "QTY_B1_27", "QTY_B1_33", "QTY_B1_34", "QTY_B1_35", "QTY_B1_36", "QTY_B1_40", "QTY_B1_41")]

# Create new column combining the daily sums of each product
B1_above$sum <- rowSums(B1_above[, grepl("^QTY_", colnames(B1_above))], na.rm = TRUE)
B1_below$sum <- rowSums(B1_below[, grepl("^QTY_", colnames(B1_below))], na.rm = TRUE)

# Create new dataset to apply to the predictive model
B1_above <- B1_above[, c("DATE", "sum")]
B1_below <- B1_below[, c("DATE", "sum")]
```

```{r}
# Split the data into training (2014-01-02 to 2017-12-31) and validation (2018-01-31 to 2018-12-31)
training_set <- subset(B1_above, DATE >= "2014-01-01" & DATE <= "2017-12-31")
validation_set <- subset(B1_above, DATE >= "2018-01-01" & DATE <= "2018-12-31")

# Display the dimensions of the training and validation sets
cat("Training Set Dimensions:", dim(training_set), "\n")
cat("Validation Set Dimensions:", dim(validation_set), "\n")
```

```{r}
B1_above
```





```{r}
# find all date and site combinations
all <- B1_above %>% 
  mutate(DATE = as.Date(DATE))  %>% 
  expand(DATE = full_seq(DATE, 1)) 

# merge back all date/site combinations to original data
B1_above_C <- B1_above %>% right_join(all, by = c("DATE")) %>% 
  mutate(sum = ifelse(is.na(sum), 
                        0, sum)) %>% 
  arrange(DATE, sum)

```






```{r}
is.ts(training_set)

```


```{r}
B1_above_ts <-ts(B1_above_C[,c(2:2)], freq = 365)
#train_sale_ts <-ts(training_set[,c(2:2)], freq = 365)
#valid_sale_ts <-ts(validation_set[,c(2:2)], freq = 365)
#train_sale_ts <-ts(training_set, freq = 365)
#train_sale_ts

```


```{r}
acf(train_sale_ts)
autoplot(B1_above_ts)
B1_above_ts
```

```{r}
#train_sale_ts
```


```{r}
train_sale_ts <- window(B1_above_ts, end = c(4,365))
valid_sale_ts <- window(B1_above_ts, start = c(5,1))
#valid_sale_ts
regsales.lm.model <- tslm(train_sale_ts ~ trend + season, train_sale_ts)

#summary(regsales.lm.model)

regsales.lm.pred <- forecast(regsales.lm.model, h = 365)

autoplot(train_sale_ts, series = 'train') +
  autolayer(valid_sale_ts, series = 'actual') +
  autolayer(regsales.lm.pred, series = 'prediction', alpha=.4) +
  theme_classic()  +
  coord_cartesian(xlim = c(1, 6))
#train_sale_ts
#valid_sale_ts
accuracy(regsales.lm.pred, valid_sale_ts)

regsales.lm.pred
```

```{r}
####BELOW
# find all date and site combinations
all <- B1_below %>% 
  mutate(DATE = as.Date(DATE))  %>% 
  expand(DATE = full_seq(DATE, 1)) 

# merge back all date/site combinations to original data
B1_below_C <- B1_below %>% right_join(all, by = c("DATE")) %>% 
  mutate(sum = ifelse(is.na(sum), 
                        0, sum)) %>% 
  arrange(DATE, sum)

B1_below_ts <-ts(B1_below_C[,c(2:2)], freq = 365)


train_sale_tsa <- window(B1_below_ts, end = c(4,365))
valid_sale_tsa <- window(B1_below_ts, start = c(5,1))
#valid_sale_ts
regsales.lm.model <- tslm(train_sale_ts ~ trend + season, train_sale_ts)

#summary(regsales.lm.model)


regsales.lm.pred <- forecast(regsales.lm.model, h = 365)

autoplot(train_sale_ts, series = 'train') +
  autolayer(valid_sale_ts, series = 'actual') +
  autolayer(regsales.lm.pred, series = 'prediction', alpha=.4) +
  theme_classic()  +
  coord_cartesian(xlim = c(1, 6))
#train_sale_ts
#valid_sale_ts
accuracy(regsales.lm.pred, valid_sale_ts)

regsales.lm.pred
```


```



**Discussion**

For this project, I was tasked with identifying with low performing item can benefit from promotional material. After reviewing the impact that promotions had on the top 10% of performing products, I decided to further familiarize myself with product QTY_B2_12 with only 1895 sales of which 2.87% account from marketing efforts. The goal is to conduct a timer series analysis to determine during which periods can this product benefit from promotions and then forecast the difference that marketing efforts can have on upcoming months. The generated information can serve as critical information for businesses to ensure sufficient inventory, confirm marketing efforts successful, understand the impact of promotions, determine seasonality, and increase sales. As a stakeholder overseeing four national pasta brands, I would want to find strategies to best improve ROI on promotional efforts for product QTY_B2_12 to increase sales to outperform the bottom 10% of products.
